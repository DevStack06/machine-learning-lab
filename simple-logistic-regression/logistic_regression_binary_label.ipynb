{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sbs\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score,auc,roc_auc_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LAB TASK-1 Start From Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "df=pd.read_csv(\"bank.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Task 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.iloc[:,0:1].values\n",
    "Y=df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## using sklearn logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=0, solver='lbfgs',multi_class='multinomial').fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7938461538461539\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.76      0.64       239\n",
      "           1       0.91      0.81      0.86       736\n",
      "\n",
      "   micro avg       0.79      0.79      0.79       975\n",
      "   macro avg       0.73      0.78      0.75       975\n",
      "weighted avg       0.82      0.79      0.80       975\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cr=classification_report(y_pred,y_test)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## using stats model logit function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.548680\n",
      "         Iterations 5\n",
      "                         Results: Logit\n",
      "================================================================\n",
      "Model:              Logit            Pseudo R-squared: 0.119    \n",
      "Dependent Variable: repaid           AIC:              3241.4062\n",
      "Date:               2019-04-29 16:27 BIC:              3247.3964\n",
      "No. Observations:   2952             Log-Likelihood:   -1619.7  \n",
      "Df Model:           0                LL-Null:          -1837.8  \n",
      "Df Residuals:       2951             LLR p-value:      nan      \n",
      "Converged:          1.0000           Scale:            1.0000   \n",
      "No. Iterations:     5.0000                                      \n",
      "-------------------------------------------------------------------\n",
      "        Coef.     Std.Err.       z       P>|z|     [0.025    0.975]\n",
      "-------------------------------------------------------------------\n",
      "x1      0.0176      0.0007    26.3156    0.0000    0.0163    0.0189\n",
      "================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "logit_model=sm.Logit(Y,X)\n",
    "result=logit_model.fit()\n",
    "print(result.summary2())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## using stats model glm function (For R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                 repaid   No. Observations:                 2952\n",
      "Model:                            GLM   Df Residuals:                     2950\n",
      "Model Family:                Binomial   Df Model:                            1\n",
      "Link Function:                  logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -1261.8\n",
      "Date:                Mon, 29 Apr 2019   Deviance:                       2523.6\n",
      "Time:                        16:27:07   Pearson chi2:                 2.63e+03\n",
      "No. Iterations:                     5   Covariance Type:             nonrobust\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     -4.2753      0.196    -21.800      0.000      -4.660      -3.891\n",
      "age            0.0840      0.003     25.683      0.000       0.078       0.090\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.formula.api as smf\n",
    " \n",
    "\n",
    "mylogit = smf.glm(formula='repaid ~ age', data=df, family=sm.families.Binomial())\n",
    "res = mylogit.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab task 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                 repaid   No. Observations:                 2952\n",
      "Model:                            GLM   Df Residuals:                     2949\n",
      "Model Family:                Binomial   Df Model:                            2\n",
      "Link Function:                  logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -770.45\n",
      "Date:                Mon, 29 Apr 2019   Deviance:                       1540.9\n",
      "Time:                        16:27:10   Pearson chi2:                 1.95e+03\n",
      "No. Iterations:                     7   Covariance Type:             nonrobust\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept    -15.5953      0.662    -23.563      0.000     -16.893     -14.298\n",
      "age            0.1570      0.006     24.199      0.000       0.144       0.170\n",
      "salary         0.1143      0.005     21.446      0.000       0.104       0.125\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "mylogit = smf.glm(formula='repaid ~ age+salary', data=df, family=sm.families.Binomial())\n",
    "res = mylogit.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Results: Generalized linear model\n",
      "================================================================\n",
      "Model:              GLM              AIC:            1546.9036  \n",
      "Link Function:      logit            BIC:            -22022.3088\n",
      "Dependent Variable: repaid           Log-Likelihood: -770.45    \n",
      "Date:               2019-04-27 15:10 LL-Null:        -1837.8    \n",
      "No. Observations:   2952             Deviance:       1540.9     \n",
      "Df Model:           2                Pearson chi2:   1.95e+03   \n",
      "Df Residuals:       2949             Scale:          1.0000     \n",
      "Method:             IRLS                                        \n",
      "----------------------------------------------------------------\n",
      "              Coef.   Std.Err.    z     P>|z|   [0.025   0.975] \n",
      "----------------------------------------------------------------\n",
      "Intercept    -15.5953   0.6619 -23.5631 0.0000 -16.8926 -14.2981\n",
      "age            0.1570   0.0065  24.1987 0.0000   0.1442   0.1697\n",
      "salary         0.1143   0.0053  21.4457 0.0000   0.1039   0.1248\n",
      "================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(res.summary2())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Task 2 Start From here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.read_csv(\"Bankloan.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df1.drop(['default','day_of_week','month','contact'],axis=1)\n",
    "df1=df1.drop(['poutcome'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df1.iloc[:,0:-1]\n",
    "Y=df1.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "job=pd.get_dummies(df1['job'],drop_first=True)\n",
    "marital=pd.get_dummies(df1['marital'],drop_first=True)\n",
    "education=pd.get_dummies(df1['education'],drop_first=True)\n",
    "housing=pd.get_dummies(df1['housing'],drop_first=True)\n",
    "loan=pd.get_dummies(df1['loan'],drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X.drop(['job','marital','education','housing','loan'],axis=1)\n",
    "X=pd.concat([X,job,marital,education,housing,loan],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9066176470588235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/balram/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=42)\n",
    "clf = LogisticRegression(random_state=0, solver='lbfgs',multi_class='multinomial').fit(X_train, y_train)\n",
    "y_pred=clf.predict(X_test)\n",
    "print(accuracy_score(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          no       0.97      0.93      0.95      1263\n",
      "         yes       0.40      0.62      0.49        97\n",
      "\n",
      "   micro avg       0.91      0.91      0.91      1360\n",
      "   macro avg       0.68      0.77      0.72      1360\n",
      "weighted avg       0.93      0.91      0.92      1360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cr=classification_report(y_pred,y_test)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                 repaid   No. Observations:                 2952\n",
      "Model:                            GLM   Df Residuals:                     2950\n",
      "Model Family:                Binomial   Df Model:                            1\n",
      "Link Function:                  logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -1261.8\n",
      "Date:                Mon, 29 Apr 2019   Deviance:                       2523.6\n",
      "Time:                        17:14:19   Pearson chi2:                 2.63e+03\n",
      "No. Iterations:                     5   Covariance Type:             nonrobust\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     -4.2753      0.196    -21.800      0.000      -4.660      -3.891\n",
      "age            0.0840      0.003     25.683      0.000       0.078       0.090\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "mylogit = smf.glm(formula='repaid ~ age', data=df, family=sm.families.Binomial())\n",
    "res = mylogit.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
